{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Out Successful Advarsarial Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../vit_base_patch16_224_in21k_test-accuracy_0.96_chest.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_path, device):\n",
    "    model = torch.load(model_path)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "[\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    # transforms.RandomRotation((90,90)),\n",
    "    # transforms.CenterCrop(400),\n",
    "    transforms.Resize((224, 224)),\n",
    "    # transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def get_blk_attn(input_img, blk, model, patch_size=16): #REVIEW:function to get mean attention of an image for a blk.\n",
    "    # a dict to store the activations\n",
    "    activation = {}\n",
    "    def getActivation(name):\n",
    "        # the hook signature\n",
    "        def hook(model, input, output):\n",
    "            activation[name] = output.detach()\n",
    "        return hook\n",
    "\n",
    "    h = model.blocks[blk].attn.attn_drop.register_forward_hook(getActivation(\"attn\"))\n",
    "\n",
    "    model.eval()\n",
    "    out = model(input_img)\n",
    "    \n",
    "    attentions = activation['attn']\n",
    "    nh = attentions.shape[1]\n",
    "    # keep only the output patch attention\n",
    "    attentions = attentions[0, :, 0, 1:].reshape(nh, -1)\n",
    "\n",
    "    w_featmap = input_img.shape[-2] // patch_size\n",
    "    h_featmap = input_img.shape[-1] // patch_size\n",
    "\n",
    "    attentions = attentions.reshape(nh, w_featmap, h_featmap)\n",
    "\n",
    "    attentions = nn.functional.interpolate(attentions.unsqueeze(\n",
    "            0), scale_factor=patch_size, mode=\"nearest\")[0].cpu().numpy()\n",
    "    attentions = attentions.transpose(0,2,1)\n",
    "    # print(attentions.shape) #REVIEW:list of attentions from each head, after interpolation. Shape = torch.Size([1, 12, 224, 224])\n",
    "    mean_attention = np.mean(attentions, 0)\n",
    "\n",
    "    return mean_attention, torch.argmax(out).item() #REVIEW:Return mean of 12 head attentions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"Normal\", \"Tuberculosis\"]\n",
    "device = 'cuda:3'\n",
    "data_path = '../data/TB_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(model_path=model_path, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_testing = [f for f in os.listdir(os.path.join(data_path, 'testing', classes[0])) if f.endswith(\".jpg\") or f.endswith(\".png\")]\n",
    "tb_testing = [f for f in os.listdir(os.path.join(data_path, 'testing', classes[1])) if f.endswith(\".jpg\") or f.endswith(\".png\")]\n",
    "normal_traning = [f for f in os.listdir(os.path.join(data_path, 'training', classes[0])) if f.endswith(\".jpg\") or f.endswith(\".png\")]\n",
    "tb_traning = [f for f in os.listdir(os.path.join(data_path, 'training', classes[1])) if f.endswith(\".jpg\") or f.endswith(\".png\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350, 2835, 350, 2835)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(normal_testing), len(normal_traning), len(tb_testing), len(tb_traning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = PIL.Image.open(os.path.join(data_path, 'testing', classes[1], tb_testing[40]))\n",
    "# img = transform(img).unsqueeze(0).to(device)\n",
    "# pred = model(img)\n",
    "# tb_testing[-1], pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.6586, -2.5522]], device='cuda:3', grad_fn=<AddmmBackward0>) Normal-1487.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-3.7917,  2.8092]], device='cuda:3', grad_fn=<AddmmBackward0>),\n",
       " 'Tuberculosis-1430.png')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = PIL.Image.open(os.path.join(data_path, 'training', classes[0], normal_traning[100]))\n",
    "img = transform(img).unsqueeze(0).to(device)\n",
    "pred = model(img)\n",
    "print(pred, normal_traning[3])\n",
    "\n",
    "\n",
    "img = PIL.Image.open(os.path.join(data_path, 'training', classes[1], tb_traning[100]))\n",
    "img = transform(img).unsqueeze(0).to(device)\n",
    "pred = model(img)\n",
    "pred, tb_traning[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save image if it fools the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "blk = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "successfull_data_path = '../data/TB_data/successfull_samples'\n",
    "os.makedirs(os.path.join(successfull_data_path, 'training', \"Normal\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(successfull_data_path, 'training', \"Tuberculosis\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(successfull_data_path, 'testing', \"Normal\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(successfull_data_path, 'testing', \"Tuberculosis\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.robust import PGD, FGSM\n",
    "import foolbox as fb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pdg(f_pgd, f_model, images, device=\"cuda:3\", eps=0.03, radius = 0.13, step_num=40, labels=torch.tensor([1]), target=0, pgd = None, attack_lib='Foolbox'):\n",
    "    # if pgd is None:\n",
    "    #     pgd = PGD(model, lower_bound=0, upper_bound=1)\n",
    "\n",
    "    # labels = torch.tensor([1])\n",
    "    adv_imgs = []\n",
    "    for input_img in tqdm(images):\n",
    "        input_img = input_img.float()\n",
    "        if attack_lib=='Foolbox':\n",
    "            _, perturbed_image, success = f_pgd(f_model, input_img.to(device), labels.to(device), epsilons=eps)\n",
    "        else:\n",
    "            perturbed_image = pgd.perturb(input_img.to(device), radius=radius, step_size=eps, step_num=step_num, target=target) #step_size = epsilon in PGD case\n",
    "        adv_img = torch.tensor((perturbed_image.cpu().data.numpy()))\n",
    "        \n",
    "        adv_imgs.append(adv_img.squeeze(0))\n",
    "    adv_imgs = torch.stack(adv_imgs)\n",
    "    return adv_imgs\n",
    "\n",
    "\n",
    "def apply_fgsm(images, device=\"cuda:3\", eps=0.03, attack_lib=\"Foolbox\", labels = torch.tensor([1]), fgsm = None, f_fgsm = None, f_model = None):    \n",
    "    adv_imgs = []\n",
    "    for input_img in tqdm(images):\n",
    "        input_img = input_img.float()\n",
    "        if attack_lib=='Foolbox':\n",
    "            _, perturbed_image, success = f_fgsm(f_model, input_img.to(device), labels.to(device), epsilons=eps)\n",
    "        else:\n",
    "            perturbed_image = fgsm.perturb(input_img.to(device), epsilon=eps, target=0) \n",
    "        adv_img = torch.tensor((perturbed_image.cpu().data.numpy()))\n",
    "        adv_imgs.append(adv_img.squeeze(0))\n",
    "    adv_imgs = torch.stack(adv_imgs)\n",
    "    return adv_imgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_test_normal = []\n",
    "for img_path in normal_testing:\n",
    "    img = PIL.Image.open(os.path.join(data_path, 'testing', classes[0], img_path))\n",
    "    img = transform(img).unsqueeze(0).to(device)\n",
    "    image_test_normal.append(img)\n",
    "\n",
    "\n",
    "image_test_tb = []\n",
    "for img_path in tb_testing:\n",
    "    img = PIL.Image.open(os.path.join(data_path, 'testing', classes[1], img_path))\n",
    "    img = transform(img).unsqueeze(0).to(device)\n",
    "    image_test_tb.append(img)\n",
    "\n",
    "\n",
    "images_train_normal = []\n",
    "for img_path in normal_traning:\n",
    "    img = PIL.Image.open(os.path.join(data_path, 'training', classes[0], img_path))\n",
    "    img = transform(img).unsqueeze(0).to(device)\n",
    "    images_train_normal.append(img)\n",
    "\n",
    "\n",
    "images_train_tb = []\n",
    "for img_path in tb_traning:\n",
    "    img = PIL.Image.open(os.path.join(data_path, 'training', classes[1], img_path))\n",
    "    img = transform(img).unsqueeze(0).to(device)\n",
    "    images_train_tb.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv_images_test_normal = apply_pdg(model, image_test_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_successful_adv_images (images_list, cls_idx):\n",
    "    selected_imgs = []\n",
    "    # selected_imgs_name = []\n",
    "    attns = []\n",
    "    for img in tqdm(images_list):\n",
    "        attn, pred = get_blk_attn(img.unsqueeze(0).to(device), blk, model)\n",
    "        if pred != cls_idx: # check if pred is not correct\n",
    "            selected_imgs.append(img.permute(1,2,0))\n",
    "            # selected_imgs_name.append(img_path)\n",
    "            attns.append(attn)\n",
    "            # break\n",
    "            # img.save(os.path.join(data_path, 'testing', classes[pred_i], img_path[:-4]+'.png'))\n",
    "            # break\n",
    "    # return selected_imgs_name, selected_imgs, attns\n",
    "    return selected_imgs, attns\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgd = PGD(model, lower_bound=0, upper_bound=1)\n",
    "f_model = fb.PyTorchModel(model, bounds=(0,1), device=device) #Foolbox's PGD\n",
    "f_pgd = fb.attacks.PGD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgsm = FGSM(model, lower_bound=0, upper_bound=1)\n",
    "f_model = fb.PyTorchModel(model, bounds=(0,1), device=device) #Foolbox's PGD\n",
    "f_fgsm = fb.attacks.FGSM()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_test_normal[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:00<00:00, 14.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 14.76it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 42.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_i = 0 # 0 --> Normal, 1 --> TB\n",
    "\n",
    "print(classes[pred_i])\n",
    "adv_images_test_normal = apply_fgsm(images=  image_test_normal[10:20], f_model=f_model, fgsm=fgsm, f_fgsm = f_fgsm, labels=torch.tensor([pred_i]), device=device)\n",
    "selected_imgs, attns = get_successful_adv_images(adv_images_test_normal, pred_i)\n",
    "len(selected_imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 350/350 [06:34<00:00,  1.13s/it]\n",
      "100%|██████████| 350/350 [00:06<00:00, 55.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 254 images to ./successful/PDG/Test/Normal\n"
     ]
    }
   ],
   "source": [
    "pred_i = 0 # 0 --> Normal, 1 --> TB\n",
    "print(classes[pred_i])\n",
    "adv_images_test_normal = apply_pdg(images=  image_test_normal, f_model=f_model, f_pgd=f_pgd, labels=torch.tensor([pred_i]))\n",
    "selected_imgs, attns = get_successful_adv_images(adv_images_test_normal, pred_i)\n",
    "\n",
    "save_folder = \"./successful/PDG/Test/Normal\"\n",
    "save_folder_attn = \"./successfull_attn/PDG/Test/Normal\"\n",
    "print(f'Saving {len(selected_imgs)} images to {save_folder}')\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "os.makedirs(save_folder_attn, exist_ok=True)\n",
    "for i, img in enumerate(selected_imgs):\n",
    "    plt.imsave(os.path.join(save_folder, f\"{i}.png\"), np.array(img))\n",
    "    np.save(os.path.join(save_folder_attn, f\"{i}.npy\"), attns[i])\n",
    "\n",
    "\n",
    "# for tuberculosis\n",
    "pred_i = 1 # 0 --> Normal, 1 --> TB\n",
    "print(classes[pred_i])\n",
    "adv_images_test_normal = apply_pdg(images=image_test_tb, f_model=f_model, f_pgd=f_pgd, labels=torch.tensor([pred_i]))\n",
    "selected_imgs, attns = get_successful_adv_images(adv_images_test_normal, pred_i)\n",
    "\n",
    "\n",
    "save_folder = \"./successful/PDG/Test/TB\"\n",
    "save_folder_attn = \"./successfull_attn/PDG/Test/TB\"\n",
    "print(f'Saving {len(selected_imgs)} images to {save_folder}')\n",
    "\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "os.makedirs(save_folder_attn, exist_ok=True)\n",
    "\n",
    "for i, img in enumerate(selected_imgs):\n",
    "    plt.imsave(os.path.join(save_folder, f\"{i}.png\"), np.array(img))\n",
    "    np.save(os.path.join(save_folder_attn, f\"{i}.npy\"), attns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2835 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2835/2835 [54:00<00:00,  1.14s/it]\n",
      "100%|██████████| 2835/2835 [00:57<00:00, 49.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 2128 images to ./successful/PDG/Train/Normal\n"
     ]
    }
   ],
   "source": [
    "# for normal training\n",
    "\n",
    "pred_i = 0 # 0 --> Normal, 1 --> TB\n",
    "print(classes[pred_i])\n",
    "adv_images_test_normal = apply_pdg(images=images_train_normal, f_model=f_model, f_pgd=f_pgd, labels=torch.tensor([pred_i]))\n",
    "selected_imgs, attns = get_successful_adv_images(adv_images_test_normal, pred_i)\n",
    "\n",
    "\n",
    "save_folder = \"./successful/PDG/Train/Normal\"\n",
    "save_folder_attn = \"./successfull_attn/PDG/Train/Normal\"\n",
    "print(f'Saving {len(selected_imgs)} images to {save_folder}')\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "os.makedirs(save_folder_attn, exist_ok=True)\n",
    "for i, img in enumerate(selected_imgs):\n",
    "    plt.imsave(os.path.join(save_folder, f\"{i}.png\"), np.array(img))\n",
    "    np.save(os.path.join(save_folder_attn, f\"{i}.npy\"), attns[i])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pred_i = 1 # 0 --> Normal, 1 --> TB\n",
    "print(classes[pred_i])\n",
    "adv_images_test_normal = apply_pdg(images= images_train_tb, f_model=f_model, f_pgd=f_pgd, labels=torch.tensor([pred_i]))\n",
    "selected_imgs, attns = get_successful_adv_images(adv_images_test_normal, pred_i)\n",
    "\n",
    "\n",
    "save_folder = \"./successful/PDG/Train/TB\"\n",
    "save_folder_attn = \"./successfull_attn/PDG/Train/TB\"\n",
    "print(f'Saving {len(selected_imgs)} images to {save_folder}')\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "os.makedirs(save_folder_attn, exist_ok=True)\n",
    "for i, img in enumerate(selected_imgs):\n",
    "    plt.imsave(os.path.join(save_folder, f\"{i}.png\"), np.array(img))\n",
    "    np.save(os.path.join(save_folder_attn, f\"{i}.npy\"), attns[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2835, 2835, 350, 350)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('../data/TB_data/training/Normal/')), len(os.listdir('../data/TB_data/training/Tuberculosis/')), len(os.listdir('../data/TB_data/testing/Normal/')), len(os.listdir('../data/TB_data/testing/Tuberculosis/'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
