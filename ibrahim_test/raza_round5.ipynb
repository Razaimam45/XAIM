{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/home/raza.imam/.conda/envs/xaim/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "/home/raza.imam/.conda/envs/xaim/lib/python3.7/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: /home/raza.imam/.conda/envs/xaim/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZNK2at10TensorBase21__dispatch_contiguousEN3c1012MemoryFormatE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from captum.robust import PGD, FGSM\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import euclidean\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "sys.path.append('../')\n",
    "from saliency import *\n",
    "from utils import *\n",
    "from plots import *\n",
    "def get_model(model_path, device):\n",
    "    model = torch.load(model_path)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda'\n",
    "MODEL_PATH = '/home/raza.imam/Documents/HC701B/Project/models/vit_base_patch16_224_in21k_test-accuracy_0.96_chest.pth'\n",
    "model = get_model(model_path=MODEL_PATH, device=DEVICE)\n",
    "\n",
    "transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Grayscale(num_output_channels=3),\n",
    "                transforms.RandomRotation((90,90)),\n",
    "                transforms.CenterCrop(200),\n",
    "                transforms.Resize((224, 224)),\n",
    "                # transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "                transforms.ToTensor(),\n",
    "                ]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_attn(img_attn_map, mean_attn_clean, mean_attn_adv, method = 'all', attacks = ['PDG', 'FGSM']): \n",
    "    \"\"\"\n",
    "        This function classifies an image as clean or adversarial \n",
    "        based on the distance between the test image's attention map \n",
    "        and the mean attention maps of clean and adversarial images.\n",
    "    \"\"\"\n",
    "    test_attn_flat = img_attn_map.flatten()\n",
    "    mean_attns_cln_flat = mean_attn_clean.flatten()\n",
    "    assert isinstance(mean_attn_adv, dict), \"mean_attn_adv must be a dict\"\n",
    "    if isinstance(method, str):\n",
    "        method = [method]\n",
    "    if \"all\" in method:\n",
    "        method = [\"sum\", \"euclidean\", \"cosine\", \"ssim\", \"kl\"]\n",
    "    preds = {}\n",
    "    \n",
    "    if \"sum\" in method:\n",
    "        sum_distance_to_normal = np.sum((test_attn_flat - mean_attns_cln_flat))\n",
    "        sum_pred = \"Clean\"\n",
    "        for key in attacks:\n",
    "            sum_distance_to_adversarial = np.sum((test_attn_flat - mean_attn_adv[key].flatten()))\n",
    "            if sum_distance_to_normal > sum_distance_to_adversarial:\n",
    "                sum_pred = \"Adversarial\"\n",
    "                break\n",
    "        preds[\"sum\"] = sum_pred\n",
    "    \n",
    "    if \"kl\" in method:\n",
    "        kl_to_normal = np.sum(kl_div(test_attn_flat, mean_attns_cln_flat))\n",
    "        kl_pred = \"Clean\"\n",
    "        for key in attacks:\n",
    "            kl_to_adversarial = np.sum(kl_div(test_attn_flat, mean_attn_adv[key].flatten()))\n",
    "            if kl_to_normal > kl_to_adversarial:\n",
    "                kl_pred = \"Adversarial\"\n",
    "                break\n",
    "        preds[\"kl\"] = kl_pred\n",
    "        \n",
    "    if \"ssim\" in method:\n",
    "        structural_similarity_to_normal = ssim(test_attn_flat, mean_attns_cln_flat)\n",
    "        structural_pred = \"Clean\"\n",
    "        for key in attacks:\n",
    "            structural_similarity_to_adversarial = ssim(test_attn_flat, mean_attn_adv[key].flatten())\n",
    "            if structural_similarity_to_normal < structural_similarity_to_adversarial:\n",
    "                structural_pred = \"Adversarial\"\n",
    "                break\n",
    "        preds[\"ssim\"] = structural_pred\n",
    "\n",
    "    if \"euclidean\" in method:\n",
    "        euc_distance_to_normal = euclidean(test_attn_flat, mean_attns_cln_flat)\n",
    "        euc_pred = \"Clean\"\n",
    "        for key in attacks:\n",
    "            euc_distance_to_adversarial = euclidean(test_attn_flat, mean_attn_adv[key].flatten())\n",
    "            if euc_distance_to_normal > euc_distance_to_adversarial:\n",
    "                euc_pred = \"Adversarial\"\n",
    "                break\n",
    "        preds[\"euclidean\"] = euc_pred\n",
    "\n",
    "    if \"cosine\" in method:\n",
    "        cosine_distance_to_normal = cosine_similarity([test_attn_flat], [mean_attns_cln_flat])\n",
    "        cos_pred = \"Clean\"\n",
    "        for key in attacks:\n",
    "            cosine_distance_to_adversarial = cosine_similarity([test_attn_flat], [mean_attn_adv[key].flatten()])\n",
    "            if cosine_distance_to_normal < cosine_distance_to_adversarial: # cosine similarity is between 0 and 1 and greater the value, more similar the vectors\n",
    "                cos_pred = \"Adversarial\"\n",
    "                break\n",
    "        preds[\"cosine\"] = cos_pred\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating references (means) using Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global vars\n",
    "attack_type = 'PDG'\n",
    "eps = 0.06\n",
    "class_type = 'Normal' #Normal, TB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2677/2677 [00:11<00:00, 228.35it/s]\n"
     ]
    }
   ],
   "source": [
    "cln_folder = f'/home/raza.imam/Documents/XAIM/XAIM/data5/training/{attack_type}_{eps}/{class_type}/Succ/Clean_x'\n",
    "\n",
    "cln_files = [f for f in os.listdir(cln_folder) if f.endswith(\".png\")]\n",
    "images = []\n",
    "for f in tqdm(cln_files):\n",
    "    image_path = os.path.join(cln_folder, f)\n",
    "    image = Image.open(image_path)\n",
    "    image = transform(image)\n",
    "    images.append(image)\n",
    "images_tensor = torch.stack(images)\n",
    "mean_attns = {}\n",
    "all_attns = {}\n",
    "mean_attn_diff = {}\n",
    "attentions_clean, mean_attns_cln = apply_attn_on_images(model=model, block=-1, images = images_tensor, device=DEVICE)\n",
    "mean_attns['clean'] = mean_attns_cln\n",
    "all_attns['clean'] = attentions_clean\n",
    "image_path = '../plots_succ/clean.png'\n",
    "plt.imsave(image_path, mean_attns['clean'], cmap='inferno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDG 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 420/420 [00:02<00:00, 191.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDG 0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2036/2036 [00:10<00:00, 201.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDG 0.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2677/2677 [00:13<00:00, 199.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGSM 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 261/261 [00:01<00:00, 219.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGSM 0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1075/1075 [00:04<00:00, 219.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGSM 0.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2203/2203 [00:10<00:00, 215.51it/s]\n"
     ]
    }
   ],
   "source": [
    "attack_type = ['PDG', 'FGSM']\n",
    "eps_list = [0.01, 0.03, 0.06]\n",
    "\n",
    "for attack in attack_type:\n",
    "    for eps in eps_list:\n",
    "        print(attack, eps)\n",
    "        atk_folder = f'/home/raza.imam/Documents/XAIM/XAIM/data5/training/{attack}_{eps}/{class_type}/Succ/Succ_x'\n",
    "\n",
    "        atk_files = [f for f in os.listdir(atk_folder) if f.endswith(\".png\")]\n",
    "        images = []\n",
    "        for f in tqdm(atk_files):\n",
    "            image_path = os.path.join(atk_folder, f)\n",
    "            image = Image.open(image_path)\n",
    "            image = transform(image)\n",
    "            images.append(image)\n",
    "        adv_images_tensor = torch.stack(images)\n",
    "\n",
    "        attentions_adv, mean_attns_adv = apply_attn_on_images(model=model, block=-1, images = adv_images_tensor, device=DEVICE)\n",
    "        mean_attns_diff_adv = mean_attns_adv - mean_attns_cln\n",
    "        mean_attns[f'{attack}_{eps}'] = mean_attns_adv\n",
    "        all_attns[f'{attack}_{eps}'] = attentions_adv\n",
    "        mean_attn_diff[f'{attack}_{eps}'] = mean_attns_diff_adv\n",
    "        image_path = f'../plots_succ/{attack}_{eps}.png'\n",
    "        plt.imsave(image_path, mean_attns[f'{attack}_{eps}'], cmap='inferno')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test attentions generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/301 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:01<00:00, 237.55it/s]\n",
      "100%|██████████| 301/301 [00:01<00:00, 196.72it/s]\n"
     ]
    }
   ],
   "source": [
    "test_attack = 'Clean_x' # Succ_x or Clean_x  \n",
    "class_name = 'Normal' # Normal or TB\n",
    "attack_type_test = 'PDG'\n",
    "\n",
    "test_folder = f'/home/raza.imam/Documents/XAIM/XAIM/data5/validation/{attack_type_test}_{eps}/{class_name}/Succ/{test_attack}'\n",
    "\n",
    "test_files = [f for f in os.listdir(test_folder) if f.endswith(\".jpg\") or f.endswith(\".png\")]\n",
    "images = []\n",
    "for f in tqdm(test_files):\n",
    "    image_path = os.path.join(test_folder, f)\n",
    "    image = Image.open(image_path)\n",
    "    image = transform(image)\n",
    "    images.append(image)\n",
    "test_images_tensor = torch.stack(images)\n",
    "test_attns = {}\n",
    "attentions_clean, _ = apply_attn_on_images(model=model, block=-1, images = test_images_tensor, device=DEVICE)\n",
    "test_attns['Clean'] = attentions_clean\n",
    "\n",
    "# ----------------------------------------------\n",
    "\n",
    "test_attack = 'Succ_x' # Succ_x or Clean_x\n",
    "class_name = 'Normal' # Normal or TB\n",
    "\n",
    "test_folder = f'/home/raza.imam/Documents/XAIM/XAIM/data5/validation/{attack_type_test}_{eps}/{class_name}/Succ/{test_attack}'\n",
    "\n",
    "test_files = [f for f in os.listdir(test_folder) if f.endswith(\".jpg\") or f.endswith(\".png\")]\n",
    "images = []\n",
    "for f in tqdm(test_files):\n",
    "    image_path = os.path.join(test_folder, f)\n",
    "    image = Image.open(image_path)\n",
    "    image = transform(image)\n",
    "    images.append(image)\n",
    "test_images_tensor = torch.stack(images)\n",
    "attentions_clean, _ = apply_attn_on_images(model=model, block=-1, images = test_images_tensor, device=DEVICE)\n",
    "test_attns['Adversarial'] = attentions_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PDG_0.01', 'PDG_0.03', 'PDG_0.06', 'FGSM_0.01', 'FGSM_0.03', 'FGSM_0.06']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [00:05, 56.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- sum ---------------\n",
      "Accuracy for sum: 0.0\n",
      "F1 score for sum: 0.0\n",
      "-------------------------------------------------------------------\n",
      "-------------------------------------------------------------------\n",
      "--------------- euclidean ---------------\n",
      "Accuracy for euclidean: 0.48172757475083056\n",
      "F1 score for euclidean: 0.6502242152466368\n",
      "-------------------------------------------------------------------\n",
      "-------------------------------------------------------------------\n",
      "--------------- cosine ---------------\n",
      "Accuracy for cosine: 0.47840531561461797\n",
      "F1 score for cosine: 0.6471910112359551\n",
      "-------------------------------------------------------------------\n",
      "-------------------------------------------------------------------\n",
      "--------------- ssim ---------------\n",
      "Accuracy for ssim: 0.4850498338870432\n",
      "F1 score for ssim: 0.6532438478747203\n",
      "-------------------------------------------------------------------\n",
      "-------------------------------------------------------------------\n",
      "--------------- kl ---------------\n",
      "Accuracy for kl: 0.5049833887043189\n",
      "F1 score for kl: 0.6710816777041942\n",
      "-------------------------------------------------------------------\n",
      "-------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gt_labels = []\n",
    "sum_preds = [] #sum_preds = ssim preds\n",
    "euc_preds = []\n",
    "cos_preds = []\n",
    "ssim_preds = []\n",
    "kl_preds = []\n",
    "\n",
    "test_attack_type='Clean'\n",
    "attacks = list(mean_attns.keys())\n",
    "attacks.remove('clean')\n",
    "print(attacks)\n",
    "\n",
    "for idx, attn_map in tqdm(enumerate(test_attns[test_attack_type])):\n",
    "    result = classify_attn(\n",
    "        img_attn_map = attn_map,\n",
    "        mean_attn_clean = mean_attns['clean'], \n",
    "        mean_attn_adv=mean_attns, \n",
    "        method='all',\n",
    "        attacks = attacks\n",
    "        )\n",
    "    sum_preds.append(result['sum'])\n",
    "    euc_preds.append(result['euclidean'])\n",
    "    cos_preds.append(result['cosine'])\n",
    "    ssim_preds.append(result['ssim'])\n",
    "    kl_preds.append(result['kl'])\n",
    "    gt_labels.append(test_attack_type)\n",
    "\n",
    "results_dict ={\n",
    "    \"GT\": gt_labels,\n",
    "    \"sum\": sum_preds,\n",
    "    \"euclidean\": euc_preds,\n",
    "    \"cosine\": cos_preds,\n",
    "    \"ssim\": ssim_preds,\n",
    "    \"kl\": kl_preds,\n",
    "}\n",
    "\n",
    "# 1 = Clean\n",
    "# 0 = Adversarial\n",
    "gt_labels_bin = [1 if label == \"Clean\" else 0 for label in gt_labels]\n",
    "\n",
    "methods = [\"sum\", \"euclidean\", \"cosine\", \"ssim\", \"kl\"]\n",
    "for method in methods:\n",
    "    pred_bin = [1 if label == \"Clean\" else 0 for label in results_dict[method]]\n",
    "    print(f'--------------- {method} ---------------')\n",
    "    print(f\"Accuracy for {method}: {accuracy_score(gt_labels_bin, pred_bin)}\")\n",
    "    print(f\"F1 score for {method}: {f1_score(gt_labels_bin, pred_bin)}\")\n",
    "    print(f'-------------------------------------------------------------------')\n",
    "    print(f'-------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "def classify_image_ssim(test_image, clean_image, adversarial_image, threshold=0.9):\n",
    "    # Calculate SSIM between test image and clean image\n",
    "    ssim_clean = ssim(test_image, clean_image, data_range=test_image.max() - test_image.min())\n",
    "\n",
    "    # Calculate SSIM between test image and adversarial image\n",
    "    ssim_adv = ssim(test_image, adversarial_image, data_range=test_image.max() - test_image.min())\n",
    "\n",
    "    # print(f\"SSIM to Clean: {ssim_clean}, SSIM to Adversarial: {ssim_adv}\")\n",
    "\n",
    "    # Compare SSIM values and classify\n",
    "    if ssim_clean > ssim_adv:\n",
    "        return \"Clean\"\n",
    "    else:\n",
    "        return \"Adversarial\"\n",
    "    \n",
    "def classify_image_sum(test_attn, mean_attns_cln, mean_attns_adv): #np.sum((test_attn - mean_attns_cln)) #FIXME:\n",
    "    # Flatten the images to 1D arrays (if not already flattened)\n",
    "    test_attn_flat = test_attn.flatten()\n",
    "    mean_attns_cln_flat = mean_attns_cln.flatten()\n",
    "    mean_attns_adv_flat = mean_attns_adv.flatten()\n",
    "    # Calculate cosine similarities\n",
    "    distance_to_normal = np.sum((test_attn_flat - mean_attns_cln_flat))\n",
    "    distance_to_adversarial = np.sum((test_attn_flat - mean_attns_adv_flat))\n",
    "\n",
    "    # print(f\"distance_to_normal: {distance_to_normal}\", f\"distance_to_adversarial: {distance_to_adversarial}\")\n",
    "    # Compare distances and classify\n",
    "    if distance_to_normal < distance_to_adversarial:\n",
    "        return \"Clean\"\n",
    "    else:\n",
    "        return \"Adversarial\"\n",
    "    \n",
    "from scipy.spatial.distance import euclidean\n",
    "# Defining function\n",
    "def classify_image_euclidean(test_attn, mean_attns_cln, mean_attns_adv): # np.sqrt(np.sum(np.square(test_attn - mean_attns_cln)))\n",
    "    # Flatten the images to 1D arrays (if not already flattened)\n",
    "    test_attn_flat = test_attn.flatten()\n",
    "    mean_attns_cln_flat = mean_attns_cln.flatten()\n",
    "    mean_attns_adv_flat = mean_attns_adv.flatten()\n",
    "    # Calculate Euclidean distances\n",
    "    distance_to_normal = euclidean(test_attn_flat, mean_attns_cln_flat)\n",
    "    distance_to_adversarial = euclidean(test_attn_flat, mean_attns_adv_flat)\n",
    "    \n",
    "    # print(f\"distance_to_normal: {distance_to_normal}\", f\"distance_to_adversarial: {distance_to_adversarial}\")\n",
    "    # Compare distances and classify\n",
    "    if distance_to_normal < distance_to_adversarial:\n",
    "        return \"Clean\"\n",
    "    else:\n",
    "        return \"Adversarial\"\n",
    "    \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Defining function\n",
    "def classify_image_cos_similarity(test_attn, mean_attns_cln, mean_attns_adv): #np.dot(test_image,normal_image)/(norm(test_image)*norm(normal_image))\n",
    "    # Flatten the images to 1D arrays (if not already flattened)\n",
    "    test_attn_flat = test_attn.flatten()\n",
    "    mean_attns_cln_flat = mean_attns_cln.flatten()\n",
    "    mean_attns_adv_flat = mean_attns_adv.flatten()\n",
    "    # Calculate cosine similarities\n",
    "    similarity_to_normal = cosine_similarity([test_attn_flat], [mean_attns_cln_flat])\n",
    "    similarity_to_adversarial = cosine_similarity([test_attn_flat], [mean_attns_adv_flat])\n",
    "\n",
    "    # print(f\"similarity_to_normal: {similarity_to_normal}\", f\"similarity_to_adversarial: {similarity_to_adversarial}\")\n",
    "    # Compare similarity scores and classify\n",
    "    if similarity_to_normal > similarity_to_adversarial:\n",
    "        return \"Clean\"\n",
    "    else:\n",
    "        return \"Adversarial\"\n",
    "\n",
    "import numpy as np\n",
    "from scipy.special import kl_div\n",
    "\n",
    "def classify_image_kl_divergence(test_attn, mean_attns_cln, mean_attns_adv):\n",
    "    # Flatten the images to 1D arrays (if not already flattened)\n",
    "    test_attn_flat = test_attn.flatten()\n",
    "    mean_attns_cln_flat = mean_attns_cln.flatten()\n",
    "    mean_attns_adv_flat = mean_attns_adv.flatten()\n",
    "    \n",
    "    # Calculate KL divergences\n",
    "    kl_to_normal = np.sum(kl_div(test_attn_flat, mean_attns_cln_flat))\n",
    "    kl_to_adversarial = np.sum(kl_div(test_attn_flat, mean_attns_adv_flat))\n",
    "\n",
    "    # Compare KL divergences and classify\n",
    "    if kl_to_normal < kl_to_adversarial:\n",
    "        return \"Clean\"\n",
    "    else :\n",
    "        return \"Adversarial\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 70.0997%\n"
     ]
    }
   ],
   "source": [
    "num_test_images = len(test_attns['Adversarial'])\n",
    "test_attns_ = test_attns['Adversarial']\n",
    "mean_attns_cln = mean_attns['clean']\n",
    "mean_attns_adv = mean_attns['FGSM_0.06']\n",
    "\n",
    "classifications = []\n",
    "# Test each test image\n",
    "for test_attn in test_attns_:\n",
    "    result = classify_image_kl_divergence(test_attn, mean_attns_cln, mean_attns_adv)\n",
    "    classifications.append(result)\n",
    "\n",
    "# Calculate accuracy\n",
    "true_labels = [\"Adversarial\"] * num_test_images  # Assuming all test images should be classified as \"Normal\"\n",
    "accuracy = sum(1 for true, predicted in zip(true_labels, classifications) if true == predicted) / num_test_images\n",
    "print(f\"Overall Accuracy: {accuracy * 100:.4f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xaim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
